{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AgBT0QH1aPR"
      },
      "outputs": [],
      "source": [
        "import re  # Regular expressions for text processing\n",
        "import csv  # CSV module to save extracted data\n",
        "import requests  # For making HTTP requests to Wikipedia\n",
        "from bs4 import BeautifulSoup  # BeautifulSoup for web scraping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wikipedia URL for highest-grossing films\n",
        "URL = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
        "# Base Wikipedia URL for deep links to movie pages\n",
        "urlfordeep = \"https://en.wikipedia.org/wiki/\"\n",
        "\n",
        "# Send an HTTP request to fetch the webpage\n",
        "response = requests.get(URL)\n",
        "response.raise_for_status()  # Raise an error if the request fails\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Find the table containing the highest-grossing films\n",
        "table = soup.find(\"table\", class_=\"wikitable\")\n",
        "\n",
        "# List to store extracted movie data\n",
        "movies = []\n"
      ],
      "metadata": {
        "id": "7dmCkScr2GcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean the director's name\n",
        "def clean_director(director) -> str:\n",
        "    l = list(director)\n",
        "    for j in range(len(l)):\n",
        "        # Allow only letters, commas, periods, and spaces\n",
        "        if l[j] not in set(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz, .\"):\n",
        "            l[j] = \"\"\n",
        "    director = \"\".join(l)  # Reassemble the cleaned text\n",
        "    return director\n",
        "\n",
        "\n",
        "# Function to clean the box office revenue format\n",
        "def cleangross(gross) -> str:\n",
        "    l = list(gross)\n",
        "    for j in range(len(l)):\n",
        "        # Allow only digits, commas, and dollar signs\n",
        "        if l[j] not in set(\"1234567890,$\"):\n",
        "            l[j] = \"\"\n",
        "    gross = \"\".join(l)  # Reassemble the cleaned text\n",
        "    return gross\n",
        "\n",
        "\n",
        "# Function to clean movie titles (removes the † symbol)\n",
        "def clean_title(title) -> str:\n",
        "    return title.replace(\"†\", \"\")"
      ],
      "metadata": {
        "id": "RnQj1rrk2K_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract additional data (Director & Country) from a movie's individual Wikipedia page\n",
        "def takedata(url) -> list:\n",
        "    response = requests.get(url)  # Fetch the movie's page\n",
        "    response.raise_for_status()  # Raise an error if the request fails\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Locate the infobox where key information is stored\n",
        "    table = soup.find(\"table\", class_=\"infobox vevent\")\n",
        "\n",
        "    # Default values in case the data is missing\n",
        "    producer = \"N/A\"\n",
        "    country = \"N/A\"\n",
        "\n",
        "    if table:\n",
        "        for row in table.find_all(\"tr\"):\n",
        "            namecols = row.find(\"th\")  # Header column (e.g., \"Directed by\", \"Country\")\n",
        "            cols = row.find(\"td\")  # Value column\n",
        "\n",
        "            if namecols and cols:\n",
        "                key = namecols.text.strip()\n",
        "\n",
        "                if key == \"Directed by\":\n",
        "                    producer = cols.text.strip()\n",
        "\n",
        "                if key in [\"Countries\", \"Country\"]:\n",
        "                    # Remove reference numbers (e.g., [1], [2]) from country names\n",
        "                    country_raw = cols.text.strip()\n",
        "                    country = re.sub(r'\\[\\d+\\]', '', country_raw).replace('\\n', ' ').strip()\n",
        "\n",
        "    return [producer, country]  # Return the extracted director and country\n",
        "\n",
        "\n",
        "# Loop through the rows of the table (excluding the header)\n",
        "for row in table.find_all(\"tr\")[1:51]:  # Only process the top 50 movies\n",
        "    cols = row.find_all(\"td\")  # Extract all <td> elements (data cells)\n",
        "    namecols = row.find_all(\"th\")  # Extract all <th> elements (title column)\n",
        "\n",
        "    if len(cols) >= 2:\n",
        "        rank = cols[0].text.strip()  # Movie ranking\n",
        "        title = namecols[0].text.strip()  # Movie title\n",
        "        gross = cols[2].text.strip()  # Box office revenue\n",
        "        year = cols[3].text.strip()  # Release year\n",
        "\n",
        "        # Get the deep link to the movie's individual Wikipedia page\n",
        "        urlData = namecols[0]\n",
        "        movurl = urlData.find(\"a\")\n",
        "        link = urlfordeep + movurl[\"href\"][6:]  # Construct full URL\n",
        "\n",
        "        # Extract director and country from the movie's Wikipedia page\n",
        "        res = takedata(link)\n",
        "\n",
        "        # Clean extracted data\n",
        "        gross = cleangross(gross)\n",
        "        res[0] = clean_director(res[0])\n",
        "        title = clean_title(title)\n",
        "\n",
        "        # Append cleaned data to the list\n",
        "        movies.append([title, year, gross, res[0], res[1]])\n"
      ],
      "metadata": {
        "id": "tb9UDKYo2PFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print extracted data to the console\n",
        "for i in movies:\n",
        "    if len(i) != 0:\n",
        "        print(f\"{i[0]} {i[1]} {i[2]} {i[3]} {i[4]} \")\n",
        "\n",
        "# Save extracted data to a CSV file\n",
        "with open(\"top_movies.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write header row\n",
        "    writer.writerow([\"Title\", \"Year\", \"Gross\", \"Director\", \"Country\"])\n",
        "\n",
        "    # Write movie data rows\n",
        "    writer.writerows(movies)\n",
        "\n",
        "print(\"Data successfully saved to 'top_movies.csv'\")"
      ],
      "metadata": {
        "id": "ubsYXXNE2XkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}